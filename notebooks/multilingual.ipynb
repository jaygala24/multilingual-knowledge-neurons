{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probing Factual Knowledge in multilingual LMs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/jaygala24/multilingual-knowledge-neurons.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/multilingual-knowledge-neurons\n",
    "!gdown --id 1Nz4q3hIdwvs82ErILR1jaBzTuU3tMR8c\n",
    "!unzip datasets.zip -d datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers einops --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from knowledge_neurons import KnowledgeNeurons, initialize_model_and_tokenizer, model_type\n",
    "from data import mpararel_expanded\n",
    "import json\n",
    "import random\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "\n",
    "# first initialize some hyperparameters\n",
    "MODEL_NAME = \"bert-base-multilingual-cased\"\n",
    "\n",
    "# these are some hyperparameters for the integrated gradients step\n",
    "BATCH_SIZE = 20\n",
    "STEPS = 20  # number of steps in the integrated grad calculation\n",
    "ADAPTIVE_THRESHOLD = 0.3  # in the paper, they find the threshold value `t` by multiplying the max attribution score by some float - this is that float.\n",
    "P = 0.5  # the threshold for the sharing percentage\n",
    "AGGREGATION_STRATEGY = \"start\"  # aggregation strategy for handling intermediate activations in case of multiple mask tokens\n",
    "LANG = \"en\"  # language to probe the LM\n",
    "REL = \"P101\"  # relation to probe the LM\n",
    "\n",
    "# setup model & tokenizer\n",
    "model, tokenizer = initialize_model_and_tokenizer(MODEL_NAME)\n",
    "\n",
    "# load dataset\n",
    "# each item in pararel is the same 'fact' (head/relation/tail) expressed in different ways\n",
    "mPARAREL = mpararel_expanded(tokenizer)\n",
    "\n",
    "# initialize the knowledge neuron wrapper with your model, tokenizer and a string expressing the type of your model ('gpt2' / 'gpt_neo' / 'bert')\n",
    "kn = KnowledgeNeurons(model, tokenizer, model_type=model_type(MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neurons(fact, verbose=False):\n",
    "    PROMPTS, GROUND_TRUTH, RELATION_NAME = (\n",
    "        fact[\"sentences\"],\n",
    "        fact[\"obj_label\"],\n",
    "        fact[\"relation_name\"],\n",
    "    )\n",
    "    PROMPTS = [p + \".\" if not p.endswith(\".\") else p for p in PROMPTS]\n",
    "\n",
    "    if verbose:\n",
    "        print(\"PROMPTS: \")\n",
    "        print(\"\\n\".join(PROMPTS))\n",
    "        print(f\"GT: {GROUND_TRUTH}\")\n",
    "        print()\n",
    "\n",
    "    refined_neurons, coarse_neurons, prompts_info = kn.get_refined_neurons(\n",
    "        prompts=PROMPTS,\n",
    "        ground_truth=GROUND_TRUTH,\n",
    "        p=P,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        steps=STEPS,\n",
    "        coarse_adaptive_threshold=ADAPTIVE_THRESHOLD,\n",
    "        aggregation_strategy=AGGREGATION_STRATEGY,\n",
    "        quiet=not verbose,\n",
    "    )\n",
    "    return [refined_neurons, coarse_neurons, prompts_info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FACTS = mPARAREL[LANG][REL]\n",
    "RESULTS = collections.defaultdict(lambda: collections.defaultdict(dict))\n",
    "RESULTS[LANG][REL] = []\n",
    "\n",
    "for FACT in tqdm(FACTS, f\"probing the LM for analyzing relations {REL} in {LANG}\"):\n",
    "    RESULTS[LANG][REL].append(get_neurons(FACT))\n",
    "\n",
    "with open(f\"mpararel_{LANG}_{REL}.json\", \"w\") as f:\n",
    "    json.dump(RESULTS, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0ced18360181a910bdd2b0b7dbe0453605940dba8f00859a59987598ad1388ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
